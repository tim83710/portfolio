{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from keras.backend.tensorflow_backend import set_session  \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "sess = tf.Session(config=config)  \n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79559\n",
      "0    C:/Users/n000171823/Desktop/KGD9分類瑕疵圖檔/trainin...\n",
      "1    C:/Users/n000171823/Desktop/KGD9分類瑕疵圖檔/trainin...\n",
      "2    C:/Users/n000171823/Desktop/KGD9分類瑕疵圖檔/trainin...\n",
      "3    C:/Users/n000171823/Desktop/KGD9分類瑕疵圖檔/trainin...\n",
      "4    C:/Users/n000171823/Desktop/KGD9分類瑕疵圖檔/trainin...\n",
      "Name: file_path, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#取得trainData\n",
    "#print(os.getcwd())\n",
    "data_path = 'C:/Users/n000171823/Desktop/PQ42'\n",
    "trainSet = pd.DataFrame([])\n",
    "# images 的路徑\n",
    "path_list = os.listdir(data_path + '/training/')\n",
    "for path in path_list:\n",
    "    fp = []\n",
    "    file_list = os.listdir(data_path + '/training/' + path + '/')\n",
    "    for f in file_list:\n",
    "        fp.append(data_path + '/training/' + path + '/' + f)\n",
    "    trainSet = pd.concat([trainSet, pd.DataFrame({'file_path':fp, 'class':path})], ignore_index=True)\n",
    "\n",
    "print(len(trainSet))\n",
    "\n",
    "if 'Thumbs' in trainSet['file_path']:\n",
    "    print('T')\n",
    "#     trainSet.drop()\n",
    "print(trainSet['file_path'][:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 01刮傷\n",
      "1 02模痕\n",
      "2 03摺痕\n",
      "3 04晶點\n",
      "4 05膠化不良\n",
      "5 06黑點\n",
      "6 07異物\n",
      "7 08破孔\n",
      "8 09結疤\n",
      "9 10油污\n",
      "10 11蚊蟲\n",
      "11 12其他\n",
      "=======================\n",
      "1     4183\n",
      "3     2335\n",
      "8     1564\n",
      "10    1004\n",
      "2      807\n",
      "5      649\n",
      "7      468\n",
      "6      439\n",
      "4      434\n",
      "9      120\n",
      "11      13\n",
      "0        6\n",
      "Name: class, dtype: int64\n",
      "12022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/n000171823/Desktop/PQ42/training/01刮傷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/n000171823/Desktop/PQ42/training/01刮傷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/n000171823/Desktop/PQ42/training/01刮傷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/n000171823/Desktop/PQ42/training/01刮傷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/n000171823/Desktop/PQ42/training/01刮傷...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path class\n",
       "0  C:/Users/n000171823/Desktop/PQ42/training/01刮傷...     0\n",
       "1  C:/Users/n000171823/Desktop/PQ42/training/01刮傷...     0\n",
       "2  C:/Users/n000171823/Desktop/PQ42/training/01刮傷...     0\n",
       "3  C:/Users/n000171823/Desktop/PQ42/training/01刮傷...     0\n",
       "4  C:/Users/n000171823/Desktop/PQ42/training/01刮傷...     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定義目標類別\n",
    "classes = ['01刮傷','02模痕','03摺痕','04晶點','05膠化不良',\n",
    "           '06黑點','07異物','08破孔','09結疤','10油污','11蚊蟲','12其他']\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    trainSet['class'][trainSet['class'] == classes[i]] = i\n",
    "trainSet.head()\n",
    "\n",
    "# print(len(classes))\n",
    "\n",
    "for i in range(0,len(classes)):\n",
    "    print(i,classes[i])\n",
    "print('=======================') \n",
    "print(trainSet['class'].value_counts())\n",
    "print(len(trainSet))\n",
    "trainSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12010\n"
     ]
    }
   ],
   "source": [
    "#shuffle data table\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "####  刪除出現 Thumbs.db 的 row\n",
    "\n",
    "del_list = []\n",
    "for i in range(0,len(trainSet)):\n",
    "    if 'Thumbs' in trainSet.loc[i,'file_path']:\n",
    "        del_list.append(i)\n",
    "\n",
    "trainSet.drop(trainSet.index[del_list], inplace=True)\n",
    "print(len(trainSet))\n",
    "\n",
    "\n",
    "df = shuffle(trainSet)\n",
    "df.head(5)\n",
    "a = df['file_path'][:1].tolist()[0]\n",
    "img = cv2.imdecode(np.fromfile(a, dtype=np.uint8), cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12010\n"
     ]
    }
   ],
   "source": [
    "#train data prepare\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#X for image data\n",
    "a=0\n",
    "X = []\n",
    "\n",
    "files = df['file_path']\n",
    "print(len(files))\n",
    "\n",
    "\n",
    "for i in files:\n",
    "    img = cv2.imdecode(np.fromfile(i, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "    img = cv2.resize(img, (128,128))\n",
    "    img = np.resize(img,(128,128,3))\n",
    "    img_new = img.astype('float32')/255\n",
    "    X.append(img_new) \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12010\n",
      "[ 2873  2475  2119 ...  3320  3408 11444]\n",
      "[ 8934  9905 11435 ...  1061  8412  6643]\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "all_index = files.index.values\n",
    "print(all_index)\n",
    "\n",
    "X_index, y_index = train_test_split( all_index, test_size=0.1, random_state=1000)\n",
    "print(X_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[1 1 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_class = np.array(df['class'])\n",
    "y = to_categorical(y_class)\n",
    "print(y[:5])\n",
    "print(y_class[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.applications import DenseNet169\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications import VGG19\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications import Xception\n",
    "from keras.applications import NASNetMobile\n",
    "import efficientnet.keras as efn\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5125 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.525 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5375 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.55 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.5625 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "img_x = 128\n",
    "img_y = 128\n",
    "img_channels = 3\n",
    "\n",
    "#接上自訂輸出\n",
    "temp_model = Sequential()\n",
    "temp_model.add(efn.EfficientNetB7(include_top=False, pooling='avg', weights='imagenet',input_shape=(img_x, img_y, img_channels)))\n",
    "temp_model.add(Dropout(0.25))\n",
    "temp_model.add(Dense(1000, input_dim=1000,\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "# temp_model.add(BatchNormalization())\n",
    "# temp_model.add(Activation('relu'))\n",
    "temp_model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b7 (Model)      (None, 2560)              64097680  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              2561000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                12012     \n",
      "=================================================================\n",
      "Total params: 66,670,692\n",
      "Trainable params: 66,359,972\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "temp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Let's train the model using Adam\n",
    "model_path = os.getcwd() + '/PQ42_model_EfficientNetB7_1.h5'\n",
    "temp_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.00005),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), cooldown=0, patience=1, min_lr=0.1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 9728 samples, validate on 1081 samples\n",
      "Epoch 1/60\n",
      "9728/9728 [==============================] - 536s 55ms/step - loss: 9.5904 - acc: 0.8304 - val_loss: 4.8846 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.88459, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 2/60\n",
      "9728/9728 [==============================] - 488s 50ms/step - loss: 2.8529 - acc: 0.9229 - val_loss: 1.3231 - val_acc: 0.9639\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.88459 to 1.32307, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 3/60\n",
      "9728/9728 [==============================] - 474s 49ms/step - loss: 0.8276 - acc: 0.9441 - val_loss: 0.4136 - val_acc: 0.9685\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.32307 to 0.41357, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 4/60\n",
      "9728/9728 [==============================] - 483s 50ms/step - loss: 0.3297 - acc: 0.9546 - val_loss: 0.1993 - val_acc: 0.9695\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.41357 to 0.19927, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 5/60\n",
      "9728/9728 [==============================] - 481s 49ms/step - loss: 0.1997 - acc: 0.9618 - val_loss: 0.1380 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.19927 to 0.13801, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 6/60\n",
      "9728/9728 [==============================] - 479s 49ms/step - loss: 0.1572 - acc: 0.9692 - val_loss: 0.1673 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.13801\n",
      "Epoch 7/60\n",
      "9728/9728 [==============================] - 490s 50ms/step - loss: 0.1131 - acc: 0.9791 - val_loss: 0.1434 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13801\n",
      "Epoch 8/60\n",
      "9728/9728 [==============================] - 488s 50ms/step - loss: 0.0954 - acc: 0.9829 - val_loss: 0.1277 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.13801 to 0.12773, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 9/60\n",
      "9728/9728 [==============================] - 477s 49ms/step - loss: 0.0855 - acc: 0.9841 - val_loss: 0.1187 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.12773 to 0.11872, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 10/60\n",
      "9728/9728 [==============================] - 480s 49ms/step - loss: 0.0814 - acc: 0.9836 - val_loss: 0.1122 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11872 to 0.11219, saving model to C:\\Users\\n000171823\\Documents/PQ42_model_EfficientNetB7_1.h5\n",
      "Epoch 11/60\n",
      "9728/9728 [==============================] - 483s 50ms/step - loss: 0.0776 - acc: 0.9863 - val_loss: 0.1131 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.11219\n",
      "Epoch 12/60\n",
      "9728/9728 [==============================] - 487s 50ms/step - loss: 0.0739 - acc: 0.9856 - val_loss: 0.1136 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.11219\n",
      "Epoch 13/60\n",
      "9728/9728 [==============================] - 489s 50ms/step - loss: 0.0715 - acc: 0.9869 - val_loss: 0.1185 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.11219\n",
      "Epoch 14/60\n",
      "9728/9728 [==============================] - 488s 50ms/step - loss: 0.0669 - acc: 0.9886 - val_loss: 0.1163 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.11219\n",
      "Epoch 15/60\n",
      "9728/9728 [==============================] - 490s 50ms/step - loss: 0.0740 - acc: 0.9870 - val_loss: 0.1168 - val_acc: 0.9759\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.11219\n",
      "Epoch 16/60\n",
      "9728/9728 [==============================] - 489s 50ms/step - loss: 0.0693 - acc: 0.9881 - val_loss: 0.1128 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.11219\n",
      "Epoch 17/60\n",
      "9728/9728 [==============================] - 489s 50ms/step - loss: 0.0699 - acc: 0.9877 - val_loss: 0.1182 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.11219\n",
      "Epoch 18/60\n",
      "9728/9728 [==============================] - 492s 51ms/step - loss: 0.0713 - acc: 0.9864 - val_loss: 0.1137 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11219\n",
      "Epoch 19/60\n",
      "9728/9728 [==============================] - 493s 51ms/step - loss: 0.0747 - acc: 0.9861 - val_loss: 0.1173 - val_acc: 0.9759\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.11219\n",
      "Epoch 20/60\n",
      "9728/9728 [==============================] - 489s 50ms/step - loss: 0.0723 - acc: 0.9875 - val_loss: 0.1157 - val_acc: 0.9759\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.11219\n",
      "Epoch 00020: early stopping\n",
      "It cost 9814.203561 sec\n",
      "9814.203560590744\n"
     ]
    }
   ],
   "source": [
    "#model_InceptionResNet.h5: epoch = 30, Lr = 0.000001\n",
    "#model_InceptionResNet2.h5: epoch = 40, Lr = 0.0001\n",
    "#model_InceptionResNet_3.h5: epoch = 40,Lr = 0.00008, add new data \n",
    "#model_InceptionResNet_4.h5: epoch = 40,Lr = 0.00008, add new data but not all\n",
    "#model_InceptionResNet_5.h5: epoch = 50,Lr = 0.000001, add new data, delete augmentation\n",
    "#model_InceptionResNet_7.h5: epoch = 60,Lr = 0.000001, dropout = 0.85, add Allen data\n",
    "\n",
    "\n",
    "import time\n",
    "tStart = time.time()#計時開始\n",
    "\n",
    "\n",
    "model_history =temp_model.fit(X_train, y_train,\n",
    "             batch_size=8,\n",
    "             epochs=60,\n",
    "             validation_split=0.1,\n",
    "             shuffle=True,\n",
    "             verbose=1,\n",
    "             callbacks=[early_stopper,checkpoint, lr_reducer])\n",
    "\n",
    "tEnd = time.time()#計時結束\n",
    "#列印結果\n",
    "print (\"It cost %f sec\" % (tEnd - tStart))\n",
    "print (tEnd - tStart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型驗證"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:/Users/n000171823/Documents/PQ42_model_EfficientNetB7_1.h5'\n",
    "model_best = load_model(model_path,compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_best.predict(X_test)\n",
    "final_pred = np.array(np.argmax(pred, axis=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201\n",
      "0    1\n",
      "1    1\n",
      "2    3\n",
      "3    5\n",
      "4    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_test = pd.DataFrame(y_test)\n",
    "y_test_class = pd.get_dummies(y_test).idxmax(1)\n",
    "print(len(y_test))\n",
    "print(y_test_class[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predict</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predict   1   2    3   4   5   6   7    8   9   10\n",
       "Label                                             \n",
       "1        422   0    0   0   0   0   0    0   0   0\n",
       "2          0  80    0   0   0   0   2    0   0   0\n",
       "3          0   0  231   0   3   0   0    0   0   0\n",
       "4          0   0    0  39   0   0   0    0   0   0\n",
       "5          0   0    3   2  56   1   0    1   0   0\n",
       "6          0   0    0   0   0  42   0    0   0   0\n",
       "7          0   1    0   0   0   0  38    1   0   0\n",
       "8          0   0    0   1   3   0   1  169   1   0\n",
       "9          0   0    0   0   0   0   0    0  10   0\n",
       "10         0   0    0   0   0   0   0    0   0  93\n",
       "11         0   0    0   0   0   0   0    1   0   0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test_class, final_pred, rownames=['Label'], colnames=['Predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用門檻值(thereshold)剔除未知圖像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Smat = model_best.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true class : 5 pred_class : 3\n",
      "true class : 5 pred_class : 3\n",
      "true class : 8 pred_class : 9\n",
      "true class : 8 pred_class : 4\n",
      "true class : 3 pred_class : 5\n",
      "true class : 3 pred_class : 5\n",
      "true class : 7 pred_class : 8\n",
      "true class : 8 pred_class : 5\n",
      "true class : 5 pred_class : 4\n",
      "true class : 5 pred_class : 4\n",
      "true class : 11 pred_class : 8\n",
      "true class : 8 pred_class : 5\n",
      "true class : 2 pred_class : 7\n",
      "true class : 7 pred_class : 2\n",
      "true class : 5 pred_class : 3\n",
      "true class : 8 pred_class : 5\n",
      "true class : 5 pred_class : 8\n",
      "true class : 3 pred_class : 5\n",
      "true class : 2 pred_class : 7\n",
      "true class : 5 pred_class : 6\n",
      "true class : 8 pred_class : 7\n",
      "[3, 237, 367, 387, 399, 447, 459, 471, 534, 555, 571, 594, 669, 800, 808, 936, 942, 1078, 1117, 1123, 1142]\n"
     ]
    }
   ],
   "source": [
    "# y_test_class != final_pred\n",
    "# print(type(y_test_class))\n",
    "# print(type(final_pred))\n",
    "\n",
    "y_test_class_1 = y_test_class.tolist()\n",
    "final_pred_1 = final_pred.tolist()\n",
    "\n",
    "y_mistake_index = []\n",
    "for i in range(0,len(y_test_class_1)):\n",
    "    if y_test_class_1[i] != final_pred_1[i]:\n",
    "        y_mistake_index.append(i)\n",
    "        print('true class :',y_test_class_1[i],'pred_class :',final_pred_1[i])\n",
    "print(y_mistake_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spmat = np.delete(Smat,y_mistake_index,axis=0)\n",
    "correct_y_test_class = np.delete(list(y_test_class),y_mistake_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, ..., 3, 8, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "thereshold = []\n",
    "for j in range(11):\n",
    "    t1 = []\n",
    "    for i in range(0,len(correct_y_test_class)):\n",
    "        if correct_y_test_class[i] == j:\n",
    "            t1.append(i)\n",
    "    if len(t1) == 0:\n",
    "        thereshold.append(0)\n",
    "    else:\n",
    "        thereshold.append(min(Spmat[t1,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.98692673,\n",
       " 0.6674977,\n",
       " 0.5074415,\n",
       " 0.9888137,\n",
       " 0.5484375,\n",
       " 0.37657553,\n",
       " 0.5610079,\n",
       " 0.45735615,\n",
       " 0.97635776,\n",
       " 0.983247]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#thereshold of model_InceptionResNet_7\n",
    "thereshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = []\n",
    "for j in range(1,11):\n",
    "    tt = []\n",
    "    for i in range(0,len(final_pred)):\n",
    "        if final_pred[i] == j:\n",
    "            tt.append(i)\n",
    "    tt = np.array(tt)\n",
    "    Smat_test_cj = Smat[tt,j]\n",
    "    unknown.append(tt[Smat_test_cj < thereshold[j]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [534, 555], [399, 936], [], [], [571], [367], []]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
